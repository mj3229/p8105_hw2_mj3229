---
title: "Homework 2"
subtitle: "Mahitha Jangeti"
output: github_document
---
Mahitha Jangeti
11/1/25
```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1
```{r}
polsmonth_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(month = month(as.integer(month), label = TRUE, abbr = FALSE),
    year = as.integer(year),) %>% 
  mutate(president = if_else(prez_gop == 1, "gop", "dem")) %>% 
  select(-prez_gop, -prez_dem, -day)
  knitr::kable(head(polsmonth_df, 8))
```

**Cleaning snp data**
```{r}
snp_df =
  read_csv("./fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year")) %>% 
 mutate(
  month = month(as.integer(month), label = TRUE, abbr = FALSE),
  year  = as.integer(year),
  year  = if_else(year > 25, 1900 + year, 2000 + year))%>% 
  select(-day) %>% 
  relocate(year, month)
  knitr::kable(head(snp_df, 8))
```

**Cleaning unemployment data**
```{r}
unemployment_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percentage_unemployment") %>% 
  mutate(    
    year = as.integer(year),
    month = recode(month,
                   jan = "January",
                   feb = "February",
                   mar = "March",
                   apr = "April",
                   may = "May",
                   jun = "June",
                   jul = "July",
                   aug = "August",
                   sep = "September",
                   oct = "October",
                   nov = "November",
                   dec = "December"))
  knitr::kable(head(unemployment_df, 8))
```


**Merging Datasets**
```{r}
final_df =
  left_join(polsmonth_df, snp_df, by = c("year", "month")) %>% 
  left_join(unemployment_df,by = c("year", "month")) %>% 
  relocate(year, month, president, close, percentage_unemployment)
  knitr::kable(head(final_df, 8))
```

## Five Thirty Eight Data Analysis

The polsmonth_df dataset contains information on number of national politicians who are democratic vs republican. It included variables such as **gov_gop**, **sen_gop**, and **rep_gop** to indicate number of republican governers/senators on associated dates and **gov_dem** etc. to indicate democratice governers/senators on associated date. The **prez_gop** variable was mutated to represented if the president was republican through a binary format (later edited). 

The snp_df dataset contains observations related to Standard & Poor's Stock market index, which is used as a representative measure of the stock market as a whole. This is indicated by the *close** closing values of the S&P stock index on the associated date (month and year).

The unemployment_df dataset contains information on the percentage of unemployment throughout the different months of the year. This is indicated by **year** and **month** that was formatted through `pivot_longer`.

The final_df dataset has a total of `r nrow(final_df)` rows and `r ncol(final_df)` columns. It is merged through the year and month columns of all three datasets. The range of years goes from `r min(final_df$year)` to 
`r max(final_df$year)` and key variables include **close**, **percentage_unemployment** , **president**, and associated dates to see politics and its relation to outcomes in unemployment rates and values of the stock index. 



## Problem 2

```{r}
trashwheel_df = 
  read_excel("./fivethirtyeight_datasets/trashwheelcollection.xlsx", 
     sheet = "Mr. Trash Wheel",
     range = "A2:N709",
     na = c("NA",".","")) %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(round(sports_balls)),
         year = as.integer(year),
         trash_wheel = "mr.trash wheel")
```

**Read and Clean Professor Trash Wheel and Gwynnda Trash Wheel sheet**
```{r}
professor_trashwheel_df =  
  read_excel( "./fivethirtyeight_datasets/trashwheelcollection.xlsx",
    sheet = "Professor Trash Wheel",
    range = "A2:L134",
    na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  mutate(
    year = as.integer(year),
    trash_wheel = "professor trash wheel")
  


gwynns_trashwheel_df =  
  read_excel( "./fivethirtyeight_datasets/trashwheelcollection.xlsx",
    sheet = "Gwynns Falls Trash Wheel",
    range = "A2:K351",
    na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  mutate(
    year = as.integer(year),
    trash_wheel = "gwynns trash wheel")
```

**Combining Datasets**
```{r}
combinewheel_df = 
  bind_rows(trashwheel_df, professor_trashwheel_df, gwynns_trashwheel_df) %>%
  janitor::clean_names() %>% 
  relocate(trash_wheel, dumpster) %>% 
  select(trash_wheel:homes_powered)
```

## Mr. Trashwheel Data Analysis
The Mr. Trashwheel dataset includes information on the Mr. Trash Wheel waster-wheel vessel and the trash it removes from the Inner Harbor. The professor_trashweel_df, trashwheel_df, and gwynns_trashwheel_df datasets give info on the litter type by the date collected and has an additional column added **trash_wheel** indicating which dataset it is from. The combinewheel_df is a combined product of the three datasets and indicated the amount of different litter collected, date of collection, and which location the data is from. 

The total weight of trash collected by Professor Trash Wheel is `r sum(professor_trashwheel_df$weight_tons, na.rm = TRUE)` tons and the total number of cigarette butts collected by Gwynnda in June of 2022 is In addition, the total number of cigarette butts collected by Gwynnda in June 2022 was 
`r gwynns_trashwheel_df %>% 
     filter(year == 2022, month == "June") %>% 
     summarise(total_cig_butts = sum(cigarette_butts, na.rm = TRUE)) %>% 
     pull(total_cig_butts)` butts.



## Problem 3

```{r}
zori_df = 
  read_csv("./zillow_data/zori.csv", na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  relocate(county_name) %>% 
  select(-state, county = county_name) %>% 
  mutate(county = county %>% 
            str_replace("New York County", "New York") %>% 
            str_replace("Kings County", "Kings") %>%
            str_replace("Queens County", "Queens") %>%
            str_replace("Bronx County", "Bronx") %>%
            str_replace("Richmond County", "Richmond")) %>% 
  rename(zip_code = region_name) %>% 
  pivot_longer(
    x2015_01_31:x2024_08_31,
    names_to = "date",
    values_to = "zillow observed rent index")
  knitr::kable(head(zori_df, 8))


neighborhood_df = 
  read_csv("./zillow_data/zip_codes.csv", na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  relocate(county, neighborhood)
  knitr::kable(head(neighborhood_df, 8))
```

**Merging Datasets**

```{r}
zillow_df = 
  left_join(zori_df, neighborhood_df, by = c("zip_code", "county"))%>%
  janitor::clean_names() %>% 
  relocate(county, neighborhood, zip_code, zillow_observed_rent_index)
  knitr::kable(head(zillow_df, 8))
```


## Zillow Data Analysis

The dataset contains a total of `r nrow(zillow_df)` observations across `r ncol(zillow_df)` variables.There are `r n_distinct(zillow_df$zip_code)` unique ZIP codes represented and `r n_distinct(zillow_df$neighborhood)` unique neighborhoods. To tidy the data, I began with zori_df and renamed county names to only include the name without "count" in order to merge datasets by the variable. Additionally, region_name was renamed to zip_code to merge. Lastly, I used `pivot_longer` to have ziro and date on two separate columns. The neighborhood_df didn't require too much tidying as I relocated the variables. Lastly, the merged dataset: zillow_df was merged through **zip_code** and **county** to display zori based on neighborhood, county, and zipcode. 

**Missing zipcodes from Zillow Rental Price dataset**

```{r}
missing_zips = 
  anti_join(neighborhood_df, zori_df, by = c("zip_code", "county"))
knitr::kable(head(missing_zips, 10))
```

Some missing zipcodes include 10464, 10474, 10475, 10499, 10550. The rest can be found from generating missing_zips. There are 174.This may be the case because some zip codes are correlated with areas that lack residential housing or that are not being rented by Zillow. They could also be associated with bigger public buildings such as airports or industrial zones. 

## Comparing Rental Prices in 2021 to 2020 

```{r}
jan_compare = 
  zillow_df %>%
  filter(date %in% c("x2020_01_31", "x2021_01_31")) %>%
  select(zip_code, county, neighborhood, date, zillow_observed_rent_index) %>% 
  pivot_wider(
    names_from = "date",
    values_from = "zillow_observed_rent_index") %>% 
  mutate(change = x2021_01_31 - x2020_01_31)
```

```{r}
top_ten =
  jan_compare %>% 
  select(change, zip_code, county, neighborhood) %>% 
  arrange(change) %>% 
  slice(1:10)
knitr::kable(head(top_ten, 10))
```

The 10 zipcodes with the largest rental price declines between January 2020 and January 2021 are mostly in Manhattan.We see neighborhoods such as Lower East Side, Soho, Chelsea, Gramercy Park, and etc. The decreases were significant as they were all higher than $600 on average. This was during covid so more people were probably moving back to the suburbs, where they wouldn't have to pay so much. They could also be moving to other boroughs that were cheaper (especially during a time of unemployment). This may have resulted in declines in rent and demand for high-cost apartments. On the other hand, boroughs such as Brooklyn or Bronx may have experienced smaller declines resulting them to not be apparent in this table.

